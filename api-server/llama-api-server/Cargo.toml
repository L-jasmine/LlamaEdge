[package]
name = "llama-api-server"
version = "0.9.0"
edition = "2021"

[dependencies]
llama-core = { path = "../llama-core", version = "^0.8" }
futures = { version = "0.3.6", default-features = false, features = ["async-await", "std"] }
serde.workspace = true
serde_json = "1.0"
endpoints.workspace = true
chat-prompts.workspace = true
serde_yaml = "0.9"
hyper = { version = "0.14", features = ["full"] }
tokio = { version = "^1.36", features = ["io-util", "fs", "net", "time", "rt", "macros"] }
thiserror.workspace = true
uuid.workspace = true
clap.workspace = true
once_cell = "1.18"
mime_guess = "2.0.4"
futures-util = "0.3"
anyhow = "1.0.80"
multipart-2021 = "0.19.0"

[features]
default = []
